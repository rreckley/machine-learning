---
title: "Coursera Practical Machine Learning course project"
author: "Roderic N. Reckley"
date: "June 6, 2016"
output: 
  html_document: 
    keep_md: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Introduction
 The use of fitness and activity movement devices such as Jawbone Up, Nike FuelBand, and Fitbit have enabled individuals to collect a large volume of data associated with their daily physical activity. The emergence of fitness devices have enabled an individual to not only track the duration of their physical activity, but how well they performed it. 
  For this project, data collected from from accelerometers on the belt, forearm, arm, and dumbbell of 6 participants in a weight lifting experiment will be evaluated. As part of the experiment, each participant in the study was asked to perform 10 repetitions of the unilateral dumbbell biceps curl correctly and incorrectly[1]. Correct execution of the curl was stored in the variable class with a value of A. Incorrect execution of the curl was stored in the variable class with a value of B, C, or E.
  
  The goal of this project is to use the data collect from this experiment to build a machine learning model that can be used to predict the execution of a bicep curl. This requires an analysis of the data set, selection of a model and then using the provided data set to train the model.

### Environment Setup
   For this project, the following libraries were used. This project was performed using R-Studio version 0.99.893 and R 3.3.0 running on 64-bit windows 7 computer.
   
```{r, message=FALSE, warning=FALSE}
library(caret)
library(rpart)
library(rpart.plot)
library(randomForest)
library(corrplot)
library(klaR)
```

### Data Retrival and Cleaning
   The training data set was downloaded from https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv
   The testing data set was downloaded from  https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv


```{r}
setwd("C:/Users/RNRECKLEY/Downloads/coursera/datascience/machine-learning/project")
trainingFile <- "./pml-training.csv"
testingFile <- "./pml-testing.csv"
rawtrainingData <- read.csv(file=trainingFile)
rawtestingData <- read.csv(file=testingFile)
```


```{r}
dim(rawtrainingData)
dim(rawtestingData)
str(rawtrainingData, list.len=20)
```

   The raw test and training data set each contain 160 variables. A brief review of the training data set indicates that the data set contains variable with value of NA. The data set may also contain variables that have very little influence on the model.
   
   The first step in cleaning the data is to identify what variables are considered as near variance predictors in the data set.
```{r}
NZVTrain <- nearZeroVar(rawtrainingData, saveMetrics = TRUE)
NZVTest <- nearZeroVar(rawtestingData, saveMetrics = TRUE)
head(NZVTrain)
```

   The second step is to remove the variables identified as near zero variance predictors from the test and training data.
```{r}
NZVtrainingData <- rawtrainingData[, !NZVTrain$nzv]
NZVtestingData <- rawtestingData[, !NZVTest$nzv]
dim(NZVtrainingData)
dim(NZVtestingData)
```

  The third step is to remove variables with values of NA.
```{r}
NAtrainingData <- NZVtrainingData[, colSums(is.na(NZVtrainingData)) == 0] 
NAtestingData <- NZVtestingData[, colSums(is.na(NZVtestingData)) == 0] 
dim(NAtrainingData)
dim(NAtestingData)
```

  The final step is to remove the remaining variables that do not coronation any accelerator data.
```{r}
cleanedTrainData <- NAtrainingData[, c(7:59)]
cleanedTestData <- NAtestingData[, c(7:59)]
dim(cleanedTrainData)
dim(cleanedTestData)
```
  
   The cleaned data sets have reduced the number of variables form 160 to 53.
   
  A correlation matrix can verify that the remaining variables are indeed correlated.
```{r}
corrplot(cor(cleanedTrainData[, -length(names(cleanedTestData))]), method = "color",tl.cex = 0.5 )
```


### Data Set Partitionining for model testing.
  
   For the next portion of the project, the cleaned training data is portioned into test and training sets for building and evaluating machine learning modules. A seed is used to ensure reproducibility of this project.
  
```{r}
set.seed(53016)
trainingPartion <- createDataPartition(y=cleanedTrainData$classe, p=0.70, list=FALSE)
ModelTrainingData <- cleanedTrainData[trainingPartion, ]
ModelTestingData <- cleanedTrainData[-trainingPartion, ]
dim(ModelTrainingData)
dim(ModelTestingData)
```
The cleaned training data set has been split into two data sets that will be used to validate the machine learning model.

### Data Modeling

#### Decision Tree
    The first step in building the model is to look at the decision tree generated by the model training data set.
```{r cache=TRUE}
TreeModel <- rpart(classe ~ ., data = ModelTrainingData, method = "class")
prp(TreeModel)
```
  From the decision tree model, we can see that roll_belt is most significant covariate in the data set. 

  The complexity of the decision tree model appears
```{r cache=TRUE}
PredictTreeModel <- predict(TreeModel, ModelTrainingData, type = "class")
confusionMatrix(ModelTrainingData$classe, PredictTreeModel)
estimated_accuracy <- postResample(PredictTreeModel, ModelTrainingData$classe)
estimated_accuracy
sample_error <- 1 - as.numeric(confusionMatrix(ModelTrainingData$classe, PredictTreeModel)$overall[1])
sample_error
```
    With an estimated accuracy of only 73%, the decision tree does not appear to be the best machine learning model to use for this particular data set. 

#### Random Forest Model
   At this point, the decision is use a random forest model with repeated cross validation. This will allow the model
  
```{r cache=TRUE}
fitControl <- trainControl(method="repeatedcv", number=5, repeats=1, verboseIter=FALSE)
fitmodel <- train(classe ~ ., data=ModelTrainingData, method="rf", trControl=fitControl)
fitmodel
```
 The random forest model used will sample 27 variables in order to predict classe.


####  Model testing with the ModelTrainingData set
```{r cache=TRUE}
predictTrainModel <- predict(fitmodel, ModelTrainingData)
confusionMatrix(ModelTrainingData$classe, predictTrainModel)
training_accuracy <- postResample(predictTrainModel, ModelTrainingData$classe)
training_accuracy
training_error <- 1 - as.numeric(confusionMatrix(ModelTrainingData$classe, predictTrainModel)$overall[1])
training_error
```
 
    The random forest model produces an estimated accuracy of 100.00% using the Model Training data set.
    The random forest model produces an out of sample error of  0% using the Model Testing data set.

    
### Model testing with the ModelTestingData set
   In this step we use the ModelTestingData set to evaluate the accuracy of the random forest based fitmodel.
```{r cache=TRUE}
predictTestModel <- predict(fitmodel, ModelTestingData)
confusionMatrix(ModelTestingData$classe, predictTestModel)
testing_accuracy <- postResample(predictTestModel, ModelTestingData$classe)
testing_accuracy
testing_error <- 1 - as.numeric(confusionMatrix(ModelTestingData$classe, predictTestModel)$overall[1])
testing_error
```
    The random forest model produces an estimated accuracy of 99.17% using the Model Testing data set.
    The random forest model produces an out of sample error of  0.82% using the Model Testing data set.
    
    The random forest model appears to be very accurate for predicting the outcome of the classe variable.

### Prediction Assignment
  The final part of the project is predict the exercise performed in cleaned test data set. The random forest base fitmodel is used to predict the exercises performed.
```{r}
finalResult <- predict(fitmodel, cleanedTestData)
finalResult
```
   A score of 20 out of 20 was received when the results were submitted to quiz online for grading.
   
## Conclusion
   The random forest based model generated for this project proved to be extremely accurate in predicting the exercises performed in the provided test data set. The high accuracy of the model can possibly be explained by the fact that the participants were coached in how to perform each task.

### References
[1] Velloso, E.; Bulling, A.; Gellersen, H.; Ugulino, W.; Fuks, H. Qualitative Activity Recognition of Weight Lifting Exercises. Proceedings of 4th International Conference in Cooperation with SIGCHI (Augmented Human '13) . Stuttgart, Germany: ACM SIGCHI, 2013.


